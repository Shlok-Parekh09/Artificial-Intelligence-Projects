{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":121144,"databundleVersionId":14484960,"sourceType":"competition"},{"sourceId":13935525,"sourceType":"datasetVersion","datasetId":8880966}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# As due to privacy Reasons we cannot show the cookies dataset publicly hence after running the code we deleted the data set\n\n# üöÄ How to Run ShikshaAI (Non-Interactive Version)\nShikshaAI automatically converts YouTube lectures into structured study packs ‚Äî no user input required during execution. It runs end-to-end using configuration values and preloaded cookies.\n# üìÅ Step 1: Upload YouTube Cookies\n### To bypass bot detection and age restrictions:\n* Log in to YouTube in your browser.\n* Use the Get cookies.txt extension.\n* Export cookies while viewing a video.\n* Upload the cookies.txt file to Kaggle as a dataset.\n* The notebook auto-detects and copies it to /kaggle/working/cookies.txt.\n\n# ‚öôÔ∏è Step 2: Configure config.yaml\n#### No prompts are used ‚Äî everything is driven by config:\n\nvideo_ids: \"UdE-W30oOXo\"  # Comma-separated YouTube video IDs\n\nchunk_length: 600         # Max audio chunk length in seconds\n\noutput_dir: \"output\"      # Where Markdown files are saved\n\nmax_workers: 2            # Parallelism for multi-video processing\n\ncookies_file: \"\"          # Leave blank; auto-detected by setup_cookies()\n\n#### To change the yt video change the video_ids section and aslo change the cookies file for new video\n\n# ‚ñ∂Ô∏è Step 3: Run the Notebook\nExecute all cells top-to-bottom.\nThe pipeline will:\n* Download audio from YouTube.\n* Transcribe using Whisper.\n* Summarize using fallback APIs (APIfy, Groq, Mistral).\n* Generate flashcards and quizzes.\n* Export everything to output/ShikshaAI_Output_<video_id>.md.\n\n# üì¶ Output\n* üì∫ Video URL\n* üìù Summary\n* üéØ Flashcards\n* üß™ Quiz\n* üé§ Transcript\n\n# 1. Setup & Dependencies\n### Purpose: - To Install required libraries and set up the environment. ###\n","metadata":{}},{"cell_type":"code","source":"!pip install -q openai-whisper cohere mistralai yt-dlp pyyaml requests ffmpeg-python --upgrade\n!apt-get -y update && apt-get -y install ffmpeg\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Explanation: ###\n\n* Installs Python packages for audio processing, API clients, and YouTube downloads.\n* Installs ffmpeg for audio/video processing.\n\n# 2. Imports & Logging #\n### Purpose: Import libraries and configure logging. ###\n","metadata":{}},{"cell_type":"code","source":"import os\nimport re\nimport yaml\nimport logging\nimport warnings\nimport subprocess\nimport whisper\nimport ffmpeg\nimport requests\nimport sys\nfrom typing import Optional\nfrom mistralai import Mistral\nfrom openai import OpenAI\nfrom concurrent.futures import ThreadPoolExecutor\nfrom concurrent.futures import ThreadPoolExecutor\nfrom kaggle_secrets import UserSecretsClient\n\n\n\n# -------------------------\n# Logging & warnings\n# -------------------------\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n    handlers=[logging.StreamHandler()]\n)\nlogger = logging.getLogger(\"shikshaai\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Explanation: ###\n* Imports all necessary libraries.\n* Configures logging to track script execution.\n\n# 3. Configuration #\n### Purpose: Load and manage configuration settings. ###\n","metadata":{}},{"cell_type":"code","source":"# -------------------------\n# Config\n# -------------------------\nCONFIG_PATH = \"config.yaml\"\nDEFAULT_CONFIG = \"\"\"\noutput_dir: \"./output\"\nmax_workers: 1\nchunk_length: 600 # seconds (10 minutes)\ncookies_file: \"\" # Path to Netscape-format cookies.txt for YouTube auth (optional)\n\"\"\"\nif not os.path.exists(CONFIG_PATH):\n    with open(CONFIG_PATH, \"w\") as f:\n        f.write(DEFAULT_CONFIG)\ndef load_config():\n    with open(CONFIG_PATH, \"r\") as f:\n        return yaml.safe_load(f)\nconfig = load_config()\nos.makedirs(config[\"output_dir\"], exist_ok=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Explanation: ###\n* Creates a default config.yaml if it doesn‚Äôt exist.\n* Loads configuration settings for output directory, workers, and chunk length.\n\n# 4. API Keys & Clients\n### Purpose: Load API keys and initialize clients.\n","metadata":{}},{"cell_type":"code","source":"# -------------------------\n# Kaggle Secrets\n# -------------------------\ntry:\n    user_secrets = UserSecretsClient()\n    APIFY_KEY = user_secrets.get_secret(\"APIFY_API_KEY\")\n    GROQ_KEY = user_secrets.get_secret(\"GROQ_API_KEY\")\n    MISTRAL_KEY = user_secrets.get_secret(\"MISTRAL_API_KEY\")\nexcept Exception as e:\n    # Fallback for local testing if not on Kaggle\n    logger.warning(\"Could not load Kaggle secrets. Ensure you are on Kaggle or set env vars manually.\")\n    APIFY_KEY = os.getenv(\"APIFY_API_KEY\")\n    GROQ_KEY = os.getenv(\"GROQ_API_KEY\")\n    MISTRAL_KEY = os.getenv(\"MISTRAL_API_KEY\")\nif not APIFY_KEY or not GROQ_KEY or not MISTRAL_KEY:\n    # Don't raise error immediately, allow script to compile, but fail later if needed\n    logger.warning(\"‚ö†Ô∏è One or more API keys are missing! The pipeline will fail at the API step.\")\n# Clients\nif GROQ_KEY:\n    groq_client = OpenAI(base_url=\"https://api.groq.com/openai/v1\", api_key=GROQ_KEY)\nif MISTRAL_KEY:\n    mistral_client = Mistral(api_key=MISTRAL_KEY)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Explanation:\n* Loads API keys from Kaggle secrets or environment variables.\n* Initializes clients for Groq and Mistral APIs.\n\n# 5. Helper Functions\n### Purpose: Utility functions for video ID extraction, filename sanitization, and audio processing.\n","metadata":{}},{"cell_type":"code","source":"# -------------------------\n# Helpers\n# -------------------------\ndef extract_video_id(url: str) -> str:\n    m = re.search(r\"(?:youtu\\.be/|v=)([A-Za-z0-9_-]{6,})\", url)\n    return m.group(1) if m else \"video\"\ndef safe_filename(s: str) -> str:\n    return \"\".join(c if c.isalnum() or c in \"-_.\" else \"_\" for c in s)\ndef get_audio_duration(file_path: str) -> float:\n    try:\n        probe = ffmpeg.probe(file_path)\n        return float(probe[\"format\"][\"duration\"])\n    except ffmpeg.Error as e:\n        logger.error(f\"FFmpeg probe failed: {e.stderr.decode() if e.stderr else str(e)}\")\n        return 0.0\ndef split_audio(input_file: str, chunk_length: int = 600):\n    if os.path.exists(\"chunks\"):\n        import shutil\n        shutil.rmtree(\"chunks\")\n    os.makedirs(\"chunks\", exist_ok=True)\n       \n    cmd = [\n        \"ffmpeg\", \"-y\", \"-i\", input_file,\n        \"-f\", \"segment\",\n        \"-segment_time\", str(chunk_length),\n        \"-c\", \"copy\", \"chunks/out%03d.mp3\"\n    ]\n    subprocess.run(cmd, check=True)\ndef choose_whisper_model(duration: float) -> str:\n    if duration < 600: # <10 min\n        return \"base\"\n    elif duration < 3600: # <1 hour\n        return \"small\"\n    else:\n        return \"medium\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Explanation:\n* extract_video_id: Extracts YouTube video ID from URL.\n* safe_filename: Sanitizes filenames.\n* get_audio_duration: Gets audio duration using ffmpeg.\n* split_audio: Splits audio into chunks for processing.\n* choose_whisper_model: Selects Whisper model based on audio duration.\n\n# 6. Transcript Agent\n### Purpose: Downloads audio from YouTube and transcribes it using Whisper.\n","metadata":{}},{"cell_type":"code","source":"# -------------------------\n# Transcript (Local Whisper)\n# -------------------------\nclass TranscriptAgent:\n    def __init__(self, chunk_length: int):\n        self.chunk_length = chunk_length\n\n    def download_audio(self, url: str, out_path: str):\n        logger.info(\"Downloading audio with yt-dlp...\")\n        cookies_file = config.get(\"cookies_file\", \"\").strip()\n        cmd = [\n            \"yt-dlp\", \"--no-warnings\", \"--cookies\", cookies_file,\n            \"-f\", \"bestaudio/best\", \"-x\", \"--audio-format\", \"mp3\",\n            \"-o\", out_path, url\n        ]\n\n        try:\n            subprocess.run(cmd, check=True)\n        except subprocess.CalledProcessError:\n            logger.warning(\"‚ö†Ô∏è bestaudio failed, retrying with fallback format...\")\n            fallback_cmd = [\n                \"yt-dlp\", \"--no-warnings\", \"--cookies\", cookies_file,\n                \"-f\", \"best\", \"-x\", \"--audio-format\", \"mp3\",\n                \"-o\", out_path, url\n            ]\n            subprocess.run(fallback_cmd, check=True)\n\n    def transcribe(self, url: str) -> str:\n        vid = extract_video_id(url)\n        audio_file = f\"temp_{vid}.mp3\"\n        if os.path.exists(audio_file):\n            os.remove(audio_file)\n\n        self.download_audio(url, audio_file)\n\n        if not os.path.exists(audio_file):\n            raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n\n        duration = get_audio_duration(audio_file)\n        model_name = choose_whisper_model(duration)\n        logger.info(f\"Loading Whisper model: {model_name}\")\n        model = whisper.load_model(model_name)\n\n        if duration <= self.chunk_length:\n            result = model.transcribe(audio_file)\n            return result[\"text\"].strip()\n\n        split_audio(audio_file, self.chunk_length)\n        transcript_parts = []\n        for chunk in sorted([c for c in os.listdir(\"chunks\") if c.endswith(\".mp3\")]):\n            result = model.transcribe(os.path.join(\"chunks\", chunk))\n            transcript_parts.append(result[\"text\"])\n        return \"\\n\".join(transcript_parts).strip()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Explanation:\n* Downloads audio from YouTube using yt-dlp.\n* Transcribes audio using Whisper, splitting long audio into chunks.\n\n# 7. Summarization\n### Purpose: Summarizes transcripts using APIfy, Groq, or Mistral.\n","metadata":{}},{"cell_type":"code","source":"# -------------------------\n# Summarization\n# -------------------------\ndef summarize_with_apify(transcript: str) -> Optional[str]:\n    if not APIFY_KEY: return None\n    url = \"https://api.apify.com/v2/acts/easyapi/text-summarization/run-sync\"\n    payload = {\"text\": transcript, \"output_sentences\": 5}\n    headers = {\"Authorization\": f\"Bearer {APIFY_KEY}\"}\n    try:\n        resp = requests.post(url, json=payload, headers=headers, timeout=120)\n        if resp.status_code == 200:\n            data = resp.json()\n            output = data.get(\"output\", [])\n            if isinstance(output, list) and len(output) > 0:\n                summary = \" \".join([item.get(\"text\", \"\") for item in output if isinstance(item, dict)])\n                return summary.strip() if summary else None\n            summary = data.get(\"summary\") or data.get(\"output\", {}).get(\"summary\", \"\")\n            return summary.strip() if summary else None\n    except Exception as e:\n        logger.warning(f\"APIfy error: {e}\")\n    return None\ndef summarize_with_groq(transcript: str) -> Optional[str]:\n    if not GROQ_KEY: return None\n    try:\n        resp = groq_client.chat.completions.create(\n            model=\"llama-3.1-8b-instant\",\n            messages=[{\"role\": \"user\", \"content\": f\"Summarize this lecture transcript into a clear outline:\\n\\n{transcript[:15000]}\"}],\n            temperature=0.3,\n            max_tokens=1000\n        )\n        return resp.choices[0].message.content.strip()\n    except Exception as e:\n        logger.warning(f\"Groq error: {e}\")\n        return None\ndef summarize_with_mistral(transcript: str) -> Optional[str]:\n    if not MISTRAL_KEY: return None\n    try:\n        resp = mistral_client.chat.complete(\n            model=\"mistral-small-2409\",\n            messages=[{\"role\": \"user\", \"content\": f\"Summarize this lecture transcript into structured notes:\\n\\n{transcript[:15000]}\"}],\n            temperature=0.3,\n            max_tokens=1200\n        )\n        return resp.choices[0].message.content.strip()\n    except Exception as e:\n        logger.warning(f\"Mistral error: {e}\")\n        return None\ndef generate_summary(transcript: str) -> str:\n    # Try providers in order\n    summary = summarize_with_apify(transcript)\n    if summary: return summary\n   \n    summary = summarize_with_groq(transcript)\n    if summary: return summary\n       \n    summary = summarize_with_mistral(transcript)\n    if summary: return summary\n       \n    raise RuntimeError(\"All summarization providers failed.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Explanation:\n* Attempts to summarize transcripts using APIfy, Groq, or Mistral in sequence.\n\n# 8. Flashcards & Quiz Generation\n### Purpose: Generates flashcards and quizzes from summaries.\n","metadata":{}},{"cell_type":"code","source":"# -------------------------\n# Flashcards & Quiz\n# -------------------------\ndef generate_flashcards(summary: str) -> str:\n    if not GROQ_KEY: return \"‚ö†Ô∏è GROQ_KEY missing.\"\n    try:\n        resp = groq_client.chat.completions.create(\n            model=\"llama-3.1-8b-instant\",\n            messages=[{\"role\": \"user\", \"content\":\n                       f\"Generate 15 Q&A flashcards from this summary. Format: Q: ... A: ...\\n\\n{summary}\"}],\n            temperature=0.4,\n            max_tokens=1200\n        )\n        return resp.choices[0].message.content.strip()\n    except Exception as e:\n        return f\"Error: {e}\"\ndef generate_quiz(summary: str) -> str:\n    if not MISTRAL_KEY: return \"‚ö†Ô∏è MISTRAL_KEY missing.\"\n    try:\n        resp = mistral_client.chat.complete(\n            model=\"mistral-small-2409\",\n            messages=[{\"role\": \"user\", \"content\":\n                       f\"Create a 10-question MCQ quiz with answers and rationales based on:\\n{summary}\"}],\n            temperature=0.4,\n            max_tokens=1500\n        )\n        return resp.choices[0].message.content.strip()\n    except Exception as e:\n        return f\"Error: {e}\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Explanation:\n* Uses Groq and Mistral to generate flashcards and quizzes.\n\n# 9. Export Agent\n### Purpose: Saves output as a Markdown file.\n","metadata":{}},{"cell_type":"code","source":"# -------------------------\n# Export\n# -------------------------\nclass ExportAgent:\n    def save_markdown(self, url: str, transcript: str, summary: str, flashcards: str, quiz: str):\n        md = f\"\"\"# üìò ShikshaAI Study Pack\n---\n## üì∫ URL\n{url}\n---\n## üìù Summary\n{summary}\n---\n## üéØ Flashcards\n{flashcards}\n---\n## üß™ Quiz\n{quiz}\n---\n## üé§ Transcript (Local Whisper)\n{transcript}\n\"\"\"\n        base_id = extract_video_id(url)\n        output_file = os.path.join(config[\"output_dir\"], f\"ShikshaAI_Output_{safe_filename(base_id)}.md\")\n        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n            f.write(md)\n        logger.info(f\"üìÑ Exported: {output_file}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Explanation:\n* Formats and saves the study pack as a Markdown file.\n\n# 10. Pipeline & Main Function\n### Purpose: Orchestrates the entire process.\n","metadata":{}},{"cell_type":"code","source":"\n# -------------------------\n# Pipeline\n# -------------------------\ndef process_url(url: str):\n    try:\n        logger.info(f\"\\n===== üîÑ Processing: {url} =====\")\n        transcriber = TranscriptAgent(config[\"chunk_length\"])\n        exporter = ExportAgent()\n       \n        transcript = transcriber.transcribe(url)\n        summary = generate_summary(transcript)\n        flashcards = generate_flashcards(summary)\n        quiz = generate_quiz(summary)\n       \n        exporter.save_markdown(url, transcript, summary, flashcards, quiz)\n        logger.info(f\"üéâ DONE! Study pack for {url} is ready.\")\n    except Exception as e:\n        logger.error(f\"‚ùå Error in pipeline for {url}: {e}\")\n\ndef input_urls() -> list:\n    # Provide IDs programmatically instead of prompting\n    ids_raw = config.get(\"video_ids\", \"h0e2HAPTGF4\")  # fallback default\n    urls = [f\"https://youtu.be/{id.strip()}\" for id in ids_raw.split(\",\") if id.strip()]\n    return urls\n\n        \n# -------------------------\n# Safe Cookies Handling\n# -------------------------\ndef setup_cookies():\n    \"\"\"\n    Safely use cookies:\n    - Copy to /kaggle/working so yt-dlp can write to it\n    - But delete BEFORE Kaggle generates output\n    \"\"\"\n\n    for root, dirs, files in os.walk(\"/kaggle/input\"):\n        if \"cookies.txt\" in files:\n            src = os.path.join(root, \"cookies.txt\")\n            dst = \"/kaggle/working/cookies.txt\"\n\n            import shutil\n            shutil.copy(src, dst)\n\n            # Use temporary location for yt-dlp\n            config[\"cookies_file\"] = dst\n            return\n\n    logger.warning(\"‚ö†Ô∏è No cookies.txt found ‚Äî yt-dlp may fail.\")\n\n\n\n\n\ndef main():\n    setup_cookies()\n    urls = input_urls()  # now returns a list without prompting\n    try:\n        with ThreadPoolExecutor(max_workers=config[\"max_workers\"]) as executor:\n            executor.map(process_url, urls)\n    except KeyboardInterrupt:\n        logger.info(\"Process interrupted by user.\")\n    except Exception as e:\n        logger.error(f\"‚ùå ERROR in main pipeline: {e}\")\n\n\nif __name__ == \"__main__\":\n    main()\n\n# ---------------------------------------------------\n# üßπ DELETE cookies BEFORE Kaggle saves output (SAFE)\n# ---------------------------------------------------\ntry:\n    cookies_path = config.get(\"cookies_file\")\n    if cookies_path and os.path.exists(cookies_path):\n        os.remove(cookies_path)\n        logger.info(\"Cookies removed from working directory for safety.\")\nexcept:\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.idle":"2025-11-30T18:19:53.744800Z","shell.execute_reply.started":"2025-11-30T18:13:36.947768Z","shell.execute_reply":"2025-11-30T18:19:53.744018Z"}},"outputs":[{"name":"stderr","text":"2025-11-30 18:19:45,131 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n2025-11-30 18:19:45,948 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n2025-11-30 18:19:53,734 - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n2025-11-30 18:19:53,736 - WARNING - WARNING: The model mistral-small-2409 is deprecated and will be removed on 2025-11-30T12:00:00+00:00. Please refer to https://docs.mistral.ai/getting-started/models/#api-versioning for more information.\n2025-11-30 18:19:53,739 - INFO - üìÑ Exported: ./output/ShikshaAI_Output_h0e2HAPTGF4.md\n2025-11-30 18:19:53,740 - INFO - üéâ DONE! Study pack for https://youtu.be/h0e2HAPTGF4 is ready.\n2025-11-30 18:19:53,741 - INFO - Cookies removed from working directory for safety.\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"### Explanation:\n\n* process_url: Processes a single URL.\n* input_urls: Returns a list of YouTube URLs.\n* setup_cookies: Copies cookies for YouTube authentication.\n* main: Orchestrates the entire pipeline.\n","metadata":{}}]}