{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47637023",
   "metadata": {
    "papermill": {
     "duration": 0.006495,
     "end_time": "2025-11-30T11:10:23.246971",
     "exception": false,
     "start_time": "2025-11-30T11:10:23.240476",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üöÄ How to Run ShikshaAI (Non-Interactive Version)\n",
    "ShikshaAI automatically converts YouTube lectures into structured study packs ‚Äî no user input required during execution. It runs end-to-end using configuration values and preloaded cookies.\n",
    "# üìÅ Step 1: Upload YouTube Cookies\n",
    "### To bypass bot detection and age restrictions:\n",
    "* Log in to YouTube in your browser.\n",
    "* Use the Get cookies.txt extension.\n",
    "* Export cookies while viewing a video.\n",
    "* Upload the cookies.txt file to Kaggle as a dataset.\n",
    "* The notebook auto-detects and copies it to /kaggle/working/cookies.txt.\n",
    "\n",
    "# ‚öôÔ∏è Step 2: Configure config.yaml\n",
    "#### No prompts are used ‚Äî everything is driven by config:\n",
    "\n",
    "video_ids: \"UdE-W30oOXo\"  # Comma-separated YouTube video IDs\n",
    "\n",
    "chunk_length: 600         # Max audio chunk length in seconds\n",
    "\n",
    "output_dir: \"output\"      # Where Markdown files are saved\n",
    "\n",
    "max_workers: 2            # Parallelism for multi-video processing\n",
    "\n",
    "cookies_file: \"\"          # Leave blank; auto-detected by setup_cookies()\n",
    "\n",
    "#### To change the yt video change the video_ids section and aslo change the cookies file for new video\n",
    "\n",
    "# ‚ñ∂Ô∏è Step 3: Run the Notebook\n",
    "Execute all cells top-to-bottom.\n",
    "The pipeline will:\n",
    "* Download audio from YouTube.\n",
    "* Transcribe using Whisper.\n",
    "* Summarize using fallback APIs (APIfy, Groq, Mistral).\n",
    "* Generate flashcards and quizzes.\n",
    "* Export everything to output/ShikshaAI_Output_<video_id>.md.\n",
    "\n",
    "# üì¶ Output\n",
    "* üì∫ Video URL\n",
    "* üìù Summary\n",
    "* üéØ Flashcards\n",
    "* üß™ Quiz\n",
    "* üé§ Transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63c5a23",
   "metadata": {
    "papermill": {
     "duration": 0.005126,
     "end_time": "2025-11-30T11:10:23.257645",
     "exception": false,
     "start_time": "2025-11-30T11:10:23.252519",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Setup & Dependencies\n",
    "### Purpose: - To Install required libraries and set up the environment. ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee20ba18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T11:10:23.270581Z",
     "iopub.status.busy": "2025-11-30T11:10:23.269379Z",
     "iopub.status.idle": "2025-11-30T11:12:26.812500Z",
     "shell.execute_reply": "2025-11-30T11:12:26.810672Z"
    },
    "papermill": {
     "duration": 123.553115,
     "end_time": "2025-11-30T11:12:26.815846",
     "exception": false,
     "start_time": "2025-11-30T11:10:23.262731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m180.0/180.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m442.8/442.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m160.3/160.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\r\n",
      "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\r\n",
      "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\r\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\r\n",
      "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\r\n",
      "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,153 kB]\r\n",
      "Get:7 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.6 kB]\r\n",
      "Get:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\r\n",
      "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\r\n",
      "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\r\n",
      "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,836 kB]\r\n",
      "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,491 kB]\r\n",
      "Get:13 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,008 kB]\r\n",
      "Get:14 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\r\n",
      "Get:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,286 kB]\r\n",
      "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,535 kB]\r\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\r\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\r\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,870 kB]\r\n",
      "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,592 kB]\r\n",
      "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,222 kB]\r\n",
      "Fetched 37.5 MB in 5s (7,575 kB/s)\r\n",
      "\r\n",
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\r\n",
      "0 upgraded, 0 newly installed, 0 to remove and 180 not upgraded.\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q openai-whisper cohere mistralai yt-dlp pyyaml requests ffmpeg-python --upgrade\n",
    "!apt-get -y update && apt-get -y install ffmpeg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61670e80",
   "metadata": {
    "papermill": {
     "duration": 0.039433,
     "end_time": "2025-11-30T11:12:26.895819",
     "exception": false,
     "start_time": "2025-11-30T11:12:26.856386",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Explanation: ###\n",
    "\n",
    "* Installs Python packages for audio processing, API clients, and YouTube downloads.\n",
    "* Installs ffmpeg for audio/video processing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7f131c",
   "metadata": {
    "papermill": {
     "duration": 0.03884,
     "end_time": "2025-11-30T11:12:26.973964",
     "exception": false,
     "start_time": "2025-11-30T11:12:26.935124",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Imports & Logging #\n",
    "### Purpose: Import libraries and configure logging. ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81e3b0c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T11:12:27.057748Z",
     "iopub.status.busy": "2025-11-30T11:12:27.056307Z",
     "iopub.status.idle": "2025-11-30T11:12:37.426018Z",
     "shell.execute_reply": "2025-11-30T11:12:37.424994Z"
    },
    "papermill": {
     "duration": 10.41365,
     "end_time": "2025-11-30T11:12:37.428118",
     "exception": false,
     "start_time": "2025-11-30T11:12:27.014468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import yaml\n",
    "import logging\n",
    "import warnings\n",
    "import subprocess\n",
    "import whisper\n",
    "import ffmpeg\n",
    "import requests\n",
    "import sys\n",
    "from typing import Optional\n",
    "from mistralai import Mistral\n",
    "from openai import OpenAI\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "# -------------------------\n",
    "# Logging & warnings\n",
    "# -------------------------\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "logger = logging.getLogger(\"shikshaai\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c07b8e9",
   "metadata": {
    "papermill": {
     "duration": 0.040098,
     "end_time": "2025-11-30T11:12:37.509169",
     "exception": false,
     "start_time": "2025-11-30T11:12:37.469071",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Explanation: ###\n",
    "* Imports all necessary libraries.\n",
    "* Configures logging to track script execution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160bf591",
   "metadata": {
    "papermill": {
     "duration": 0.039122,
     "end_time": "2025-11-30T11:12:37.587466",
     "exception": false,
     "start_time": "2025-11-30T11:12:37.548344",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Configuration #\n",
    "### Purpose: Load and manage configuration settings. ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06353f50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T11:12:37.667703Z",
     "iopub.status.busy": "2025-11-30T11:12:37.667167Z",
     "iopub.status.idle": "2025-11-30T11:12:37.676882Z",
     "shell.execute_reply": "2025-11-30T11:12:37.675930Z"
    },
    "papermill": {
     "duration": 0.051745,
     "end_time": "2025-11-30T11:12:37.678794",
     "exception": false,
     "start_time": "2025-11-30T11:12:37.627049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Config\n",
    "# -------------------------\n",
    "CONFIG_PATH = \"config.yaml\"\n",
    "DEFAULT_CONFIG = \"\"\"\n",
    "output_dir: \"./output\"\n",
    "max_workers: 1\n",
    "chunk_length: 600 # seconds (10 minutes)\n",
    "cookies_file: \"\" # Path to Netscape-format cookies.txt for YouTube auth (optional)\n",
    "\"\"\"\n",
    "if not os.path.exists(CONFIG_PATH):\n",
    "    with open(CONFIG_PATH, \"w\") as f:\n",
    "        f.write(DEFAULT_CONFIG)\n",
    "def load_config():\n",
    "    with open(CONFIG_PATH, \"r\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "config = load_config()\n",
    "os.makedirs(config[\"output_dir\"], exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4cd0a5",
   "metadata": {
    "papermill": {
     "duration": 0.041125,
     "end_time": "2025-11-30T11:12:37.759789",
     "exception": false,
     "start_time": "2025-11-30T11:12:37.718664",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Explanation: ###\n",
    "* Creates a default config.yaml if it doesn‚Äôt exist.\n",
    "* Loads configuration settings for output directory, workers, and chunk length.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20363f9b",
   "metadata": {
    "papermill": {
     "duration": 0.039265,
     "end_time": "2025-11-30T11:12:37.838753",
     "exception": false,
     "start_time": "2025-11-30T11:12:37.799488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. API Keys & Clients\n",
    "### Purpose: Load API keys and initialize clients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cad893af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T11:12:37.928737Z",
     "iopub.status.busy": "2025-11-30T11:12:37.928347Z",
     "iopub.status.idle": "2025-11-30T11:12:38.686363Z",
     "shell.execute_reply": "2025-11-30T11:12:38.685075Z"
    },
    "papermill": {
     "duration": 0.805745,
     "end_time": "2025-11-30T11:12:38.688408",
     "exception": false,
     "start_time": "2025-11-30T11:12:37.882663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Kaggle Secrets\n",
    "# -------------------------\n",
    "try:\n",
    "    user_secrets = UserSecretsClient()\n",
    "    APIFY_KEY = user_secrets.get_secret(\"APIFY_API_KEY\")\n",
    "    GROQ_KEY = user_secrets.get_secret(\"GROQ_API_KEY\")\n",
    "    MISTRAL_KEY = user_secrets.get_secret(\"MISTRAL_API_KEY\")\n",
    "except Exception as e:\n",
    "    # Fallback for local testing if not on Kaggle\n",
    "    logger.warning(\"Could not load Kaggle secrets. Ensure you are on Kaggle or set env vars manually.\")\n",
    "    APIFY_KEY = os.getenv(\"APIFY_API_KEY\")\n",
    "    GROQ_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "    MISTRAL_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "if not APIFY_KEY or not GROQ_KEY or not MISTRAL_KEY:\n",
    "    # Don't raise error immediately, allow script to compile, but fail later if needed\n",
    "    logger.warning(\"‚ö†Ô∏è One or more API keys are missing! The pipeline will fail at the API step.\")\n",
    "# Clients\n",
    "if GROQ_KEY:\n",
    "    groq_client = OpenAI(base_url=\"https://api.groq.com/openai/v1\", api_key=GROQ_KEY)\n",
    "if MISTRAL_KEY:\n",
    "    mistral_client = Mistral(api_key=MISTRAL_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f844fbe",
   "metadata": {
    "papermill": {
     "duration": 0.040078,
     "end_time": "2025-11-30T11:12:38.770073",
     "exception": false,
     "start_time": "2025-11-30T11:12:38.729995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Explanation:\n",
    "* Loads API keys from Kaggle secrets or environment variables.\n",
    "* Initializes clients for Groq and Mistral APIs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670d7791",
   "metadata": {
    "papermill": {
     "duration": 0.038547,
     "end_time": "2025-11-30T11:12:38.846850",
     "exception": false,
     "start_time": "2025-11-30T11:12:38.808303",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Helper Functions\n",
    "### Purpose: Utility functions for video ID extraction, filename sanitization, and audio processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ac411f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T11:12:38.925416Z",
     "iopub.status.busy": "2025-11-30T11:12:38.924324Z",
     "iopub.status.idle": "2025-11-30T11:12:38.935108Z",
     "shell.execute_reply": "2025-11-30T11:12:38.934110Z"
    },
    "papermill": {
     "duration": 0.05171,
     "end_time": "2025-11-30T11:12:38.936782",
     "exception": false,
     "start_time": "2025-11-30T11:12:38.885072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "def extract_video_id(url: str) -> str:\n",
    "    m = re.search(r\"(?:youtu\\.be/|v=)([A-Za-z0-9_-]{6,})\", url)\n",
    "    return m.group(1) if m else \"video\"\n",
    "def safe_filename(s: str) -> str:\n",
    "    return \"\".join(c if c.isalnum() or c in \"-_.\" else \"_\" for c in s)\n",
    "def get_audio_duration(file_path: str) -> float:\n",
    "    try:\n",
    "        probe = ffmpeg.probe(file_path)\n",
    "        return float(probe[\"format\"][\"duration\"])\n",
    "    except ffmpeg.Error as e:\n",
    "        logger.error(f\"FFmpeg probe failed: {e.stderr.decode() if e.stderr else str(e)}\")\n",
    "        return 0.0\n",
    "def split_audio(input_file: str, chunk_length: int = 600):\n",
    "    if os.path.exists(\"chunks\"):\n",
    "        import shutil\n",
    "        shutil.rmtree(\"chunks\")\n",
    "    os.makedirs(\"chunks\", exist_ok=True)\n",
    "       \n",
    "    cmd = [\n",
    "        \"ffmpeg\", \"-y\", \"-i\", input_file,\n",
    "        \"-f\", \"segment\",\n",
    "        \"-segment_time\", str(chunk_length),\n",
    "        \"-c\", \"copy\", \"chunks/out%03d.mp3\"\n",
    "    ]\n",
    "    subprocess.run(cmd, check=True)\n",
    "def choose_whisper_model(duration: float) -> str:\n",
    "    if duration < 600: # <10 min\n",
    "        return \"base\"\n",
    "    elif duration < 3600: # <1 hour\n",
    "        return \"small\"\n",
    "    else:\n",
    "        return \"medium\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0b8ab1",
   "metadata": {
    "papermill": {
     "duration": 0.038664,
     "end_time": "2025-11-30T11:12:39.013854",
     "exception": false,
     "start_time": "2025-11-30T11:12:38.975190",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Explanation:\n",
    "* extract_video_id: Extracts YouTube video ID from URL.\n",
    "* safe_filename: Sanitizes filenames.\n",
    "* get_audio_duration: Gets audio duration using ffmpeg.\n",
    "* split_audio: Splits audio into chunks for processing.\n",
    "* choose_whisper_model: Selects Whisper model based on audio duration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a023d69",
   "metadata": {
    "papermill": {
     "duration": 0.037963,
     "end_time": "2025-11-30T11:12:39.090054",
     "exception": false,
     "start_time": "2025-11-30T11:12:39.052091",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. Transcript Agent\n",
    "### Purpose: Downloads audio from YouTube and transcribes it using Whisper.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93aac62c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T11:12:39.170365Z",
     "iopub.status.busy": "2025-11-30T11:12:39.169977Z",
     "iopub.status.idle": "2025-11-30T11:12:39.182641Z",
     "shell.execute_reply": "2025-11-30T11:12:39.181507Z"
    },
    "papermill": {
     "duration": 0.055202,
     "end_time": "2025-11-30T11:12:39.185077",
     "exception": false,
     "start_time": "2025-11-30T11:12:39.129875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Transcript (Local Whisper)\n",
    "# -------------------------\n",
    "class TranscriptAgent:\n",
    "    def __init__(self, chunk_length: int):\n",
    "        self.chunk_length = chunk_length\n",
    "\n",
    "    def download_audio(self, url: str, out_path: str):\n",
    "        logger.info(\"Downloading audio with yt-dlp...\")\n",
    "        cookies_file = config.get(\"cookies_file\", \"\").strip()\n",
    "        cmd = [\n",
    "            \"yt-dlp\", \"--no-warnings\", \"--cookies\", cookies_file,\n",
    "            \"-f\", \"bestaudio/best\", \"-x\", \"--audio-format\", \"mp3\",\n",
    "            \"-o\", out_path, url\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            subprocess.run(cmd, check=True)\n",
    "        except subprocess.CalledProcessError:\n",
    "            logger.warning(\"‚ö†Ô∏è bestaudio failed, retrying with fallback format...\")\n",
    "            fallback_cmd = [\n",
    "                \"yt-dlp\", \"--no-warnings\", \"--cookies\", cookies_file,\n",
    "                \"-f\", \"best\", \"-x\", \"--audio-format\", \"mp3\",\n",
    "                \"-o\", out_path, url\n",
    "            ]\n",
    "            subprocess.run(fallback_cmd, check=True)\n",
    "\n",
    "    def transcribe(self, url: str) -> str:\n",
    "        vid = extract_video_id(url)\n",
    "        audio_file = f\"temp_{vid}.mp3\"\n",
    "        if os.path.exists(audio_file):\n",
    "            os.remove(audio_file)\n",
    "\n",
    "        self.download_audio(url, audio_file)\n",
    "\n",
    "        if not os.path.exists(audio_file):\n",
    "            raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "\n",
    "        duration = get_audio_duration(audio_file)\n",
    "        model_name = choose_whisper_model(duration)\n",
    "        logger.info(f\"Loading Whisper model: {model_name}\")\n",
    "        model = whisper.load_model(model_name)\n",
    "\n",
    "        if duration <= self.chunk_length:\n",
    "            result = model.transcribe(audio_file)\n",
    "            return result[\"text\"].strip()\n",
    "\n",
    "        split_audio(audio_file, self.chunk_length)\n",
    "        transcript_parts = []\n",
    "        for chunk in sorted([c for c in os.listdir(\"chunks\") if c.endswith(\".mp3\")]):\n",
    "            result = model.transcribe(os.path.join(\"chunks\", chunk))\n",
    "            transcript_parts.append(result[\"text\"])\n",
    "        return \"\\n\".join(transcript_parts).strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94dbebb",
   "metadata": {
    "papermill": {
     "duration": 0.039503,
     "end_time": "2025-11-30T11:12:39.268154",
     "exception": false,
     "start_time": "2025-11-30T11:12:39.228651",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Explanation:\n",
    "* Downloads audio from YouTube using yt-dlp.\n",
    "* Transcribes audio using Whisper, splitting long audio into chunks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae414bd7",
   "metadata": {
    "papermill": {
     "duration": 0.038483,
     "end_time": "2025-11-30T11:12:39.345602",
     "exception": false,
     "start_time": "2025-11-30T11:12:39.307119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7. Summarization\n",
    "### Purpose: Summarizes transcripts using APIfy, Groq, or Mistral.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84dd7ef3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T11:12:39.426945Z",
     "iopub.status.busy": "2025-11-30T11:12:39.426591Z",
     "iopub.status.idle": "2025-11-30T11:12:39.439511Z",
     "shell.execute_reply": "2025-11-30T11:12:39.438392Z"
    },
    "papermill": {
     "duration": 0.055637,
     "end_time": "2025-11-30T11:12:39.441446",
     "exception": false,
     "start_time": "2025-11-30T11:12:39.385809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Summarization\n",
    "# -------------------------\n",
    "def summarize_with_apify(transcript: str) -> Optional[str]:\n",
    "    if not APIFY_KEY: return None\n",
    "    url = \"https://api.apify.com/v2/acts/easyapi/text-summarization/run-sync\"\n",
    "    payload = {\"text\": transcript, \"output_sentences\": 5}\n",
    "    headers = {\"Authorization\": f\"Bearer {APIFY_KEY}\"}\n",
    "    try:\n",
    "        resp = requests.post(url, json=payload, headers=headers, timeout=120)\n",
    "        if resp.status_code == 200:\n",
    "            data = resp.json()\n",
    "            output = data.get(\"output\", [])\n",
    "            if isinstance(output, list) and len(output) > 0:\n",
    "                summary = \" \".join([item.get(\"text\", \"\") for item in output if isinstance(item, dict)])\n",
    "                return summary.strip() if summary else None\n",
    "            summary = data.get(\"summary\") or data.get(\"output\", {}).get(\"summary\", \"\")\n",
    "            return summary.strip() if summary else None\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"APIfy error: {e}\")\n",
    "    return None\n",
    "def summarize_with_groq(transcript: str) -> Optional[str]:\n",
    "    if not GROQ_KEY: return None\n",
    "    try:\n",
    "        resp = groq_client.chat.completions.create(\n",
    "            model=\"llama-3.1-8b-instant\",\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"Summarize this lecture transcript into a clear outline:\\n\\n{transcript[:15000]}\"}],\n",
    "            temperature=0.3,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "        return resp.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Groq error: {e}\")\n",
    "        return None\n",
    "def summarize_with_mistral(transcript: str) -> Optional[str]:\n",
    "    if not MISTRAL_KEY: return None\n",
    "    try:\n",
    "        resp = mistral_client.chat.complete(\n",
    "            model=\"mistral-small-2409\",\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"Summarize this lecture transcript into structured notes:\\n\\n{transcript[:15000]}\"}],\n",
    "            temperature=0.3,\n",
    "            max_tokens=1200\n",
    "        )\n",
    "        return resp.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Mistral error: {e}\")\n",
    "        return None\n",
    "def generate_summary(transcript: str) -> str:\n",
    "    # Try providers in order\n",
    "    summary = summarize_with_apify(transcript)\n",
    "    if summary: return summary\n",
    "   \n",
    "    summary = summarize_with_groq(transcript)\n",
    "    if summary: return summary\n",
    "       \n",
    "    summary = summarize_with_mistral(transcript)\n",
    "    if summary: return summary\n",
    "       \n",
    "    raise RuntimeError(\"All summarization providers failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b150fe1",
   "metadata": {
    "papermill": {
     "duration": 0.05644,
     "end_time": "2025-11-30T11:12:39.536912",
     "exception": false,
     "start_time": "2025-11-30T11:12:39.480472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Explanation:\n",
    "* Attempts to summarize transcripts using APIfy, Groq, or Mistral in sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ef3f78",
   "metadata": {
    "papermill": {
     "duration": 0.043622,
     "end_time": "2025-11-30T11:12:39.632364",
     "exception": false,
     "start_time": "2025-11-30T11:12:39.588742",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 8. Flashcards & Quiz Generation\n",
    "### Purpose: Generates flashcards and quizzes from summaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36bbf008",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T11:12:39.913207Z",
     "iopub.status.busy": "2025-11-30T11:12:39.912834Z",
     "iopub.status.idle": "2025-11-30T11:12:39.920854Z",
     "shell.execute_reply": "2025-11-30T11:12:39.919712Z"
    },
    "papermill": {
     "duration": 0.049664,
     "end_time": "2025-11-30T11:12:39.922590",
     "exception": false,
     "start_time": "2025-11-30T11:12:39.872926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Flashcards & Quiz\n",
    "# -------------------------\n",
    "def generate_flashcards(summary: str) -> str:\n",
    "    if not GROQ_KEY: return \"‚ö†Ô∏è GROQ_KEY missing.\"\n",
    "    try:\n",
    "        resp = groq_client.chat.completions.create(\n",
    "            model=\"llama-3.1-8b-instant\",\n",
    "            messages=[{\"role\": \"user\", \"content\":\n",
    "                       f\"Generate 15 Q&A flashcards from this summary. Format: Q: ... A: ...\\n\\n{summary}\"}],\n",
    "            temperature=0.4,\n",
    "            max_tokens=1200\n",
    "        )\n",
    "        return resp.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "def generate_quiz(summary: str) -> str:\n",
    "    if not MISTRAL_KEY: return \"‚ö†Ô∏è MISTRAL_KEY missing.\"\n",
    "    try:\n",
    "        resp = mistral_client.chat.complete(\n",
    "            model=\"mistral-small-2409\",\n",
    "            messages=[{\"role\": \"user\", \"content\":\n",
    "                       f\"Create a 10-question MCQ quiz with answers and rationales based on:\\n{summary}\"}],\n",
    "            temperature=0.4,\n",
    "            max_tokens=1500\n",
    "        )\n",
    "        return resp.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ae75f7",
   "metadata": {
    "papermill": {
     "duration": 0.038785,
     "end_time": "2025-11-30T11:12:40.000737",
     "exception": false,
     "start_time": "2025-11-30T11:12:39.961952",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Explanation:\n",
    "* Uses Groq and Mistral to generate flashcards and quizzes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54e6947",
   "metadata": {
    "papermill": {
     "duration": 0.038347,
     "end_time": "2025-11-30T11:12:40.077972",
     "exception": false,
     "start_time": "2025-11-30T11:12:40.039625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 9. Export Agent\n",
    "### Purpose: Saves output as a Markdown file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebde2bc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T11:12:40.160054Z",
     "iopub.status.busy": "2025-11-30T11:12:40.159696Z",
     "iopub.status.idle": "2025-11-30T11:12:40.166331Z",
     "shell.execute_reply": "2025-11-30T11:12:40.165376Z"
    },
    "papermill": {
     "duration": 0.04925,
     "end_time": "2025-11-30T11:12:40.168125",
     "exception": false,
     "start_time": "2025-11-30T11:12:40.118875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Export\n",
    "# -------------------------\n",
    "class ExportAgent:\n",
    "    def save_markdown(self, url: str, transcript: str, summary: str, flashcards: str, quiz: str):\n",
    "        md = f\"\"\"# üìò ShikshaAI Study Pack\n",
    "---\n",
    "## üì∫ URL\n",
    "{url}\n",
    "---\n",
    "## üìù Summary\n",
    "{summary}\n",
    "---\n",
    "## üéØ Flashcards\n",
    "{flashcards}\n",
    "---\n",
    "## üß™ Quiz\n",
    "{quiz}\n",
    "---\n",
    "## üé§ Transcript (Local Whisper)\n",
    "{transcript}\n",
    "\"\"\"\n",
    "        base_id = extract_video_id(url)\n",
    "        output_file = os.path.join(config[\"output_dir\"], f\"ShikshaAI_Output_{safe_filename(base_id)}.md\")\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(md)\n",
    "        logger.info(f\"üìÑ Exported: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa1365c",
   "metadata": {
    "papermill": {
     "duration": 0.039679,
     "end_time": "2025-11-30T11:12:40.247320",
     "exception": false,
     "start_time": "2025-11-30T11:12:40.207641",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Explanation:\n",
    "* Formats and saves the study pack as a Markdown file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdfa47b",
   "metadata": {
    "papermill": {
     "duration": 0.038832,
     "end_time": "2025-11-30T11:12:40.326140",
     "exception": false,
     "start_time": "2025-11-30T11:12:40.287308",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 10. Pipeline & Main Function\n",
    "### Purpose: Orchestrates the entire process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "870a0182",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T11:12:40.407338Z",
     "iopub.status.busy": "2025-11-30T11:12:40.406886Z",
     "iopub.status.idle": "2025-11-30T11:13:28.658018Z",
     "shell.execute_reply": "2025-11-30T11:13:28.656903Z"
    },
    "papermill": {
     "duration": 48.294489,
     "end_time": "2025-11-30T11:13:28.660110",
     "exception": false,
     "start_time": "2025-11-30T11:12:40.365621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 11:12:40,432 - INFO - ‚úÖ Copied cookies file to writable location: /kaggle/working/cookies.txt\n",
      "2025-11-30 11:12:40,435 - INFO - \n",
      "===== üîÑ Processing: https://youtu.be/UdE-W30oOXo =====\n",
      "2025-11-30 11:12:40,437 - INFO - Downloading audio with yt-dlp...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://youtu.be/UdE-W30oOXo\n",
      "[youtube] UdE-W30oOXo: Downloading webpage\n",
      "[youtube] UdE-W30oOXo: Downloading android sdkless player API JSON\n",
      "[youtube] UdE-W30oOXo: Downloading web safari player API JSON\n",
      "[youtube] UdE-W30oOXo: Downloading m3u8 information\n",
      "[info] UdE-W30oOXo: Downloading 1 format(s): 251\n",
      "[download] Sleeping 6.00 seconds as required by the site...\n",
      "[download] Destination: temp_UdE-W30oOXo.webm\n",
      "[download] 100% of    2.45MiB in 00:00:00 at 22.07MiB/s  \n",
      "[ExtractAudio] Destination: temp_UdE-W30oOXo.mp3\n",
      "Deleting original file temp_UdE-W30oOXo.webm (pass -k to keep)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 11:12:54,623 - INFO - Loading Whisper model: base\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 139M/139M [00:01<00:00, 120MiB/s]\n",
      "2025-11-30 11:13:18,582 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-30 11:13:19,229 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-30 11:13:28,647 - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-30 11:13:28,651 - INFO - üìÑ Exported: ./output/ShikshaAI_Output_UdE-W30oOXo.md\n",
      "2025-11-30 11:13:28,652 - INFO - üéâ DONE! Study pack for https://youtu.be/UdE-W30oOXo is ready.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------\n",
    "# Pipeline\n",
    "# -------------------------\n",
    "def process_url(url: str):\n",
    "    try:\n",
    "        logger.info(f\"\\n===== üîÑ Processing: {url} =====\")\n",
    "        transcriber = TranscriptAgent(config[\"chunk_length\"])\n",
    "        exporter = ExportAgent()\n",
    "       \n",
    "        transcript = transcriber.transcribe(url)\n",
    "        summary = generate_summary(transcript)\n",
    "        flashcards = generate_flashcards(summary)\n",
    "        quiz = generate_quiz(summary)\n",
    "       \n",
    "        exporter.save_markdown(url, transcript, summary, flashcards, quiz)\n",
    "        logger.info(f\"üéâ DONE! Study pack for {url} is ready.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Error in pipeline for {url}: {e}\")\n",
    "\n",
    "def input_urls() -> list:\n",
    "    # Provide IDs programmatically instead of prompting\n",
    "    ids_raw = config.get(\"video_ids\", \"UdE-W30oOXo\")  # fallback default\n",
    "    urls = [f\"https://youtu.be/{id.strip()}\" for id in ids_raw.split(\",\") if id.strip()]\n",
    "    return urls\n",
    "\n",
    "        \n",
    "def setup_cookies():\n",
    "    # Step 1: Auto-detect cookies.txt in Kaggle datasets\n",
    "    for root, dirs, files in os.walk(\"/kaggle/input\"):\n",
    "        if \"cookies.txt\" in files:\n",
    "            src = os.path.join(root, \"cookies.txt\")\n",
    "            dst = \"/kaggle/working/cookies.txt\"\n",
    "\n",
    "            # ‚úÖ Only copy if source and destination are different\n",
    "            if os.path.abspath(src) != os.path.abspath(dst):\n",
    "                import shutil\n",
    "                shutil.copy(src, dst)\n",
    "                logger.info(f\"‚úÖ Copied cookies file to writable location: {dst}\")\n",
    "            else:\n",
    "                logger.info(f\"‚úÖ Cookies file already in writable location: {dst}\")\n",
    "\n",
    "            config[\"cookies_file\"] = dst\n",
    "            with open(CONFIG_PATH, \"w\") as f:\n",
    "                yaml.dump(config, f)\n",
    "            return\n",
    "\n",
    "    # Step 2: Check if config already has a valid cookies file\n",
    "    cookies_file = config.get(\"cookies_file\", \"\").strip()\n",
    "    if cookies_file and os.path.exists(cookies_file):\n",
    "        logger.info(f\"Using existing cookies file: {cookies_file}\")\n",
    "        return\n",
    "\n",
    "    # Step 3: No fallback ‚Äî just warn\n",
    "    logger.warning(\"‚ö†Ô∏è No cookies.txt found. YouTube downloads may fail due to bot detection.\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    setup_cookies()\n",
    "    urls = input_urls()  # now returns a list without prompting\n",
    "    try:\n",
    "        with ThreadPoolExecutor(max_workers=config[\"max_workers\"]) as executor:\n",
    "            executor.map(process_url, urls)\n",
    "    except KeyboardInterrupt:\n",
    "        logger.info(\"Process interrupted by user.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå ERROR in main pipeline: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2a7e51",
   "metadata": {
    "papermill": {
     "duration": 0.040615,
     "end_time": "2025-11-30T11:13:28.742644",
     "exception": false,
     "start_time": "2025-11-30T11:13:28.702029",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Explanation:\n",
    "\n",
    "* process_url: Processes a single URL.\n",
    "* input_urls: Returns a list of YouTube URLs.\n",
    "* setup_cookies: Copies cookies for YouTube authentication.\n",
    "* main: Orchestrates the entire pipeline.\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8876005,
     "sourceId": 13928684,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 193.615174,
   "end_time": "2025-11-30T11:13:31.423197",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-30T11:10:17.808023",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
