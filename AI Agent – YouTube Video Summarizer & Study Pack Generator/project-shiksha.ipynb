{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6873ddb7",
   "metadata": {
    "papermill": {
     "duration": 0.00391,
     "end_time": "2025-11-30T18:20:52.025017",
     "exception": false,
     "start_time": "2025-11-30T18:20:52.021107",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# As due to privacy Reasons we cannot show the cookies dataset publicly hence after running the code I deleted the data set\n",
    "\n",
    "# üöÄ How to Run ShikshaAI (Non-Interactive Version)\n",
    "ShikshaAI automatically converts YouTube lectures into structured study packs ‚Äî no user input required during execution. It runs end-to-end using configuration values and preloaded cookies.\n",
    "# üìÅ Step 1: Upload YouTube Cookies\n",
    "### To bypass bot detection and age restrictions:\n",
    "* Log in to YouTube in your browser.\n",
    "* Use the Get cookies.txt extension.\n",
    "* Export cookies while viewing a video.\n",
    "* Upload the cookies.txt file to Kaggle as a dataset.\n",
    "* The notebook auto-detects and copies it to /kaggle/working/cookies.txt.\n",
    "\n",
    "# ‚öôÔ∏è Step 2: Configure config.yaml\n",
    "#### No prompts are used ‚Äî everything is driven by config:\n",
    "\n",
    "video_ids: \"UdE-W30oOXo\"  # Comma-separated YouTube video IDs\n",
    "\n",
    "chunk_length: 600         # Max audio chunk length in seconds\n",
    "\n",
    "output_dir: \"output\"      # Where Markdown files are saved\n",
    "\n",
    "max_workers: 2            # Parallelism for multi-video processing\n",
    "\n",
    "cookies_file: \"\"          # Leave blank; auto-detected by setup_cookies()\n",
    "\n",
    "#### To change the yt video change the video_ids section and aslo change the cookies file for new video\n",
    "\n",
    "# ‚ñ∂Ô∏è Step 3: Run the Notebook\n",
    "Execute all cells top-to-bottom.\n",
    "The pipeline will:\n",
    "* Download audio from YouTube.\n",
    "* Transcribe using Whisper.\n",
    "* Summarize using fallback APIs (APIfy, Groq, Mistral).\n",
    "* Generate flashcards and quizzes.\n",
    "* Export everything to output/ShikshaAI_Output_<video_id>.md.\n",
    "\n",
    "# üì¶ Output\n",
    "* üì∫ Video URL\n",
    "* üìù Summary\n",
    "* üéØ Flashcards\n",
    "* üß™ Quiz\n",
    "* üé§ Transcript\n",
    "\n",
    "# 1. Setup & Dependencies\n",
    "### Purpose: - To Install required libraries and set up the environment. ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f3302fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:20:52.031781Z",
     "iopub.status.busy": "2025-11-30T18:20:52.031527Z",
     "iopub.status.idle": "2025-11-30T18:22:34.728607Z",
     "shell.execute_reply": "2025-11-30T18:22:34.727644Z"
    },
    "papermill": {
     "duration": 102.702136,
     "end_time": "2025-11-30T18:22:34.730162",
     "exception": false,
     "start_time": "2025-11-30T18:20:52.028026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m180.0/180.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m442.8/442.8 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m160.3/160.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\r\n",
      "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\r\n",
      "Get:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\r\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\r\n",
      "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\r\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\r\n",
      "Get:7 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.6 kB]\r\n",
      "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,153 kB]\r\n",
      "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,491 kB]\r\n",
      "Get:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\r\n",
      "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\r\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\r\n",
      "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\r\n",
      "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,535 kB]\r\n",
      "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,836 kB]\r\n",
      "Get:16 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\r\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,592 kB]\r\n",
      "Get:18 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,008 kB]\r\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,870 kB]\r\n",
      "Get:20 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,286 kB]\r\n",
      "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,222 kB]\r\n",
      "Fetched 37.5 MB in 3s (13.8 MB/s)\r\n",
      "\r\n",
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\r\n",
      "0 upgraded, 0 newly installed, 0 to remove and 180 not upgraded.\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q openai-whisper cohere mistralai yt-dlp pyyaml requests ffmpeg-python --upgrade\n",
    "!apt-get -y update && apt-get -y install ffmpeg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220456f0",
   "metadata": {
    "papermill": {
     "duration": 0.026351,
     "end_time": "2025-11-30T18:22:34.784432",
     "exception": false,
     "start_time": "2025-11-30T18:22:34.758081",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Explanation: ###\n",
    "\n",
    "* Installs Python packages for audio processing, API clients, and YouTube downloads.\n",
    "* Installs ffmpeg for audio/video processing.\n",
    "\n",
    "# 2. Imports & Logging #\n",
    "### Purpose: Import libraries and configure logging. ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f43160c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:22:34.839247Z",
     "iopub.status.busy": "2025-11-30T18:22:34.838641Z",
     "iopub.status.idle": "2025-11-30T18:22:43.905321Z",
     "shell.execute_reply": "2025-11-30T18:22:43.904695Z"
    },
    "papermill": {
     "duration": 9.095515,
     "end_time": "2025-11-30T18:22:43.906625",
     "exception": false,
     "start_time": "2025-11-30T18:22:34.811110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import yaml\n",
    "import logging\n",
    "import warnings\n",
    "import subprocess\n",
    "import whisper\n",
    "import ffmpeg\n",
    "import requests\n",
    "import sys\n",
    "from typing import Optional\n",
    "from mistralai import Mistral\n",
    "from openai import OpenAI\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Logging & warnings\n",
    "# -------------------------\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "logger = logging.getLogger(\"shikshaai\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44d698e",
   "metadata": {
    "papermill": {
     "duration": 0.026039,
     "end_time": "2025-11-30T18:22:43.959780",
     "exception": false,
     "start_time": "2025-11-30T18:22:43.933741",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Explanation: ###\n",
    "* Imports all necessary libraries.\n",
    "* Configures logging to track script execution.\n",
    "\n",
    "# 3. Configuration #\n",
    "### Purpose: Load and manage configuration settings. ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d00efc1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:22:44.013401Z",
     "iopub.status.busy": "2025-11-30T18:22:44.012641Z",
     "iopub.status.idle": "2025-11-30T18:22:44.019695Z",
     "shell.execute_reply": "2025-11-30T18:22:44.019181Z"
    },
    "papermill": {
     "duration": 0.0349,
     "end_time": "2025-11-30T18:22:44.020747",
     "exception": false,
     "start_time": "2025-11-30T18:22:43.985847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Config\n",
    "# -------------------------\n",
    "CONFIG_PATH = \"config.yaml\"\n",
    "DEFAULT_CONFIG = \"\"\"\n",
    "output_dir: \"./output\"\n",
    "max_workers: 1\n",
    "chunk_length: 600 # seconds (10 minutes)\n",
    "cookies_file: \"\" # Path to Netscape-format cookies.txt for YouTube auth (optional)\n",
    "\"\"\"\n",
    "if not os.path.exists(CONFIG_PATH):\n",
    "    with open(CONFIG_PATH, \"w\") as f:\n",
    "        f.write(DEFAULT_CONFIG)\n",
    "def load_config():\n",
    "    with open(CONFIG_PATH, \"r\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "config = load_config()\n",
    "os.makedirs(config[\"output_dir\"], exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d981eaf6",
   "metadata": {
    "papermill": {
     "duration": 0.025622,
     "end_time": "2025-11-30T18:22:44.072970",
     "exception": false,
     "start_time": "2025-11-30T18:22:44.047348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Explanation: ###\n",
    "* Creates a default config.yaml if it doesn‚Äôt exist.\n",
    "* Loads configuration settings for output directory, workers, and chunk length.\n",
    "\n",
    "# 4. API Keys & Clients\n",
    "### Purpose: Load API keys and initialize clients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a2cb09c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:22:44.126534Z",
     "iopub.status.busy": "2025-11-30T18:22:44.126309Z",
     "iopub.status.idle": "2025-11-30T18:22:44.740947Z",
     "shell.execute_reply": "2025-11-30T18:22:44.740285Z"
    },
    "papermill": {
     "duration": 0.643197,
     "end_time": "2025-11-30T18:22:44.742344",
     "exception": false,
     "start_time": "2025-11-30T18:22:44.099147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Kaggle Secrets\n",
    "# -------------------------\n",
    "try:\n",
    "    user_secrets = UserSecretsClient()\n",
    "    APIFY_KEY = user_secrets.get_secret(\"APIFY_API_KEY\")\n",
    "    GROQ_KEY = user_secrets.get_secret(\"GROQ_API_KEY\")\n",
    "    MISTRAL_KEY = user_secrets.get_secret(\"MISTRAL_API_KEY\")\n",
    "except Exception as e:\n",
    "    # Fallback for local testing if not on Kaggle\n",
    "    logger.warning(\"Could not load Kaggle secrets. Ensure you are on Kaggle or set env vars manually.\")\n",
    "    APIFY_KEY = os.getenv(\"APIFY_API_KEY\")\n",
    "    GROQ_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "    MISTRAL_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "if not APIFY_KEY or not GROQ_KEY or not MISTRAL_KEY:\n",
    "    # Don't raise error immediately, allow script to compile, but fail later if needed\n",
    "    logger.warning(\"‚ö†Ô∏è One or more API keys are missing! The pipeline will fail at the API step.\")\n",
    "# Clients\n",
    "if GROQ_KEY:\n",
    "    groq_client = OpenAI(base_url=\"https://api.groq.com/openai/v1\", api_key=GROQ_KEY)\n",
    "if MISTRAL_KEY:\n",
    "    mistral_client = Mistral(api_key=MISTRAL_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35be3bab",
   "metadata": {
    "papermill": {
     "duration": 0.025632,
     "end_time": "2025-11-30T18:22:44.795311",
     "exception": false,
     "start_time": "2025-11-30T18:22:44.769679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Explanation:\n",
    "* Loads API keys from Kaggle secrets or environment variables.\n",
    "* Initializes clients for Groq and Mistral APIs.\n",
    "\n",
    "# 5. Helper Functions\n",
    "### Purpose: Utility functions for video ID extraction, filename sanitization, and audio processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f9ccad1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:22:44.847746Z",
     "iopub.status.busy": "2025-11-30T18:22:44.847300Z",
     "iopub.status.idle": "2025-11-30T18:22:44.853929Z",
     "shell.execute_reply": "2025-11-30T18:22:44.853375Z"
    },
    "papermill": {
     "duration": 0.034032,
     "end_time": "2025-11-30T18:22:44.854942",
     "exception": false,
     "start_time": "2025-11-30T18:22:44.820910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "def extract_video_id(url: str) -> str:\n",
    "    m = re.search(r\"(?:youtu\\.be/|v=)([A-Za-z0-9_-]{6,})\", url)\n",
    "    return m.group(1) if m else \"video\"\n",
    "def safe_filename(s: str) -> str:\n",
    "    return \"\".join(c if c.isalnum() or c in \"-_.\" else \"_\" for c in s)\n",
    "def get_audio_duration(file_path: str) -> float:\n",
    "    try:\n",
    "        probe = ffmpeg.probe(file_path)\n",
    "        return float(probe[\"format\"][\"duration\"])\n",
    "    except ffmpeg.Error as e:\n",
    "        logger.error(f\"FFmpeg probe failed: {e.stderr.decode() if e.stderr else str(e)}\")\n",
    "        return 0.0\n",
    "def split_audio(input_file: str, chunk_length: int = 600):\n",
    "    if os.path.exists(\"chunks\"):\n",
    "        import shutil\n",
    "        shutil.rmtree(\"chunks\")\n",
    "    os.makedirs(\"chunks\", exist_ok=True)\n",
    "       \n",
    "    cmd = [\n",
    "        \"ffmpeg\", \"-y\", \"-i\", input_file,\n",
    "        \"-f\", \"segment\",\n",
    "        \"-segment_time\", str(chunk_length),\n",
    "        \"-c\", \"copy\", \"chunks/out%03d.mp3\"\n",
    "    ]\n",
    "    subprocess.run(cmd, check=True)\n",
    "def choose_whisper_model(duration: float) -> str:\n",
    "    if duration < 600: # <10 min\n",
    "        return \"base\"\n",
    "    elif duration < 3600: # <1 hour\n",
    "        return \"small\"\n",
    "    else:\n",
    "        return \"medium\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c326df2",
   "metadata": {
    "papermill": {
     "duration": 0.027385,
     "end_time": "2025-11-30T18:22:44.908806",
     "exception": false,
     "start_time": "2025-11-30T18:22:44.881421",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Explanation:\n",
    "* extract_video_id: Extracts YouTube video ID from URL.\n",
    "* safe_filename: Sanitizes filenames.\n",
    "* get_audio_duration: Gets audio duration using ffmpeg.\n",
    "* split_audio: Splits audio into chunks for processing.\n",
    "* choose_whisper_model: Selects Whisper model based on audio duration.\n",
    "\n",
    "# 6. Transcript Agent\n",
    "### Purpose: Downloads audio from YouTube and transcribes it using Whisper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43f7c62d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:22:44.961653Z",
     "iopub.status.busy": "2025-11-30T18:22:44.961440Z",
     "iopub.status.idle": "2025-11-30T18:22:44.968431Z",
     "shell.execute_reply": "2025-11-30T18:22:44.967898Z"
    },
    "papermill": {
     "duration": 0.034784,
     "end_time": "2025-11-30T18:22:44.969399",
     "exception": false,
     "start_time": "2025-11-30T18:22:44.934615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Transcript (Local Whisper)\n",
    "# -------------------------\n",
    "class TranscriptAgent:\n",
    "    def __init__(self, chunk_length: int):\n",
    "        self.chunk_length = chunk_length\n",
    "\n",
    "    def download_audio(self, url: str, out_path: str):\n",
    "        logger.info(\"Downloading audio with yt-dlp...\")\n",
    "        cookies_file = config.get(\"cookies_file\", \"\").strip()\n",
    "        cmd = [\n",
    "            \"yt-dlp\", \"--no-warnings\", \"--cookies\", cookies_file,\n",
    "            \"-f\", \"bestaudio/best\", \"-x\", \"--audio-format\", \"mp3\",\n",
    "            \"-o\", out_path, url\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            subprocess.run(cmd, check=True)\n",
    "        except subprocess.CalledProcessError:\n",
    "            logger.warning(\"‚ö†Ô∏è bestaudio failed, retrying with fallback format...\")\n",
    "            fallback_cmd = [\n",
    "                \"yt-dlp\", \"--no-warnings\", \"--cookies\", cookies_file,\n",
    "                \"-f\", \"best\", \"-x\", \"--audio-format\", \"mp3\",\n",
    "                \"-o\", out_path, url\n",
    "            ]\n",
    "            subprocess.run(fallback_cmd, check=True)\n",
    "\n",
    "    def transcribe(self, url: str) -> str:\n",
    "        vid = extract_video_id(url)\n",
    "        audio_file = f\"temp_{vid}.mp3\"\n",
    "        if os.path.exists(audio_file):\n",
    "            os.remove(audio_file)\n",
    "\n",
    "        self.download_audio(url, audio_file)\n",
    "\n",
    "        if not os.path.exists(audio_file):\n",
    "            raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "\n",
    "        duration = get_audio_duration(audio_file)\n",
    "        model_name = choose_whisper_model(duration)\n",
    "        logger.info(f\"Loading Whisper model: {model_name}\")\n",
    "        model = whisper.load_model(model_name)\n",
    "\n",
    "        if duration <= self.chunk_length:\n",
    "            result = model.transcribe(audio_file)\n",
    "            return result[\"text\"].strip()\n",
    "\n",
    "        split_audio(audio_file, self.chunk_length)\n",
    "        transcript_parts = []\n",
    "        for chunk in sorted([c for c in os.listdir(\"chunks\") if c.endswith(\".mp3\")]):\n",
    "            result = model.transcribe(os.path.join(\"chunks\", chunk))\n",
    "            transcript_parts.append(result[\"text\"])\n",
    "        return \"\\n\".join(transcript_parts).strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6c8677",
   "metadata": {
    "papermill": {
     "duration": 0.026011,
     "end_time": "2025-11-30T18:22:45.021377",
     "exception": false,
     "start_time": "2025-11-30T18:22:44.995366",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Explanation:\n",
    "* Downloads audio from YouTube using yt-dlp.\n",
    "* Transcribes audio using Whisper, splitting long audio into chunks.\n",
    "\n",
    "# 7. Summarization\n",
    "### Purpose: Summarizes transcripts using APIfy, Groq, or Mistral.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97a9f80d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:22:45.075018Z",
     "iopub.status.busy": "2025-11-30T18:22:45.074659Z",
     "iopub.status.idle": "2025-11-30T18:22:45.082862Z",
     "shell.execute_reply": "2025-11-30T18:22:45.082288Z"
    },
    "papermill": {
     "duration": 0.036113,
     "end_time": "2025-11-30T18:22:45.083936",
     "exception": false,
     "start_time": "2025-11-30T18:22:45.047823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Summarization\n",
    "# -------------------------\n",
    "def summarize_with_apify(transcript: str) -> Optional[str]:\n",
    "    if not APIFY_KEY: return None\n",
    "    url = \"https://api.apify.com/v2/acts/easyapi/text-summarization/run-sync\"\n",
    "    payload = {\"text\": transcript, \"output_sentences\": 5}\n",
    "    headers = {\"Authorization\": f\"Bearer {APIFY_KEY}\"}\n",
    "    try:\n",
    "        resp = requests.post(url, json=payload, headers=headers, timeout=120)\n",
    "        if resp.status_code == 200:\n",
    "            data = resp.json()\n",
    "            output = data.get(\"output\", [])\n",
    "            if isinstance(output, list) and len(output) > 0:\n",
    "                summary = \" \".join([item.get(\"text\", \"\") for item in output if isinstance(item, dict)])\n",
    "                return summary.strip() if summary else None\n",
    "            summary = data.get(\"summary\") or data.get(\"output\", {}).get(\"summary\", \"\")\n",
    "            return summary.strip() if summary else None\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"APIfy error: {e}\")\n",
    "    return None\n",
    "def summarize_with_groq(transcript: str) -> Optional[str]:\n",
    "    if not GROQ_KEY: return None\n",
    "    try:\n",
    "        resp = groq_client.chat.completions.create(\n",
    "            model=\"llama-3.1-8b-instant\",\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"Summarize this lecture transcript into a clear outline:\\n\\n{transcript[:15000]}\"}],\n",
    "            temperature=0.3,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "        return resp.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Groq error: {e}\")\n",
    "        return None\n",
    "def summarize_with_mistral(transcript: str) -> Optional[str]:\n",
    "    if not MISTRAL_KEY: return None\n",
    "    try:\n",
    "        resp = mistral_client.chat.complete(\n",
    "            model=\"mistral-small-2409\",\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"Summarize this lecture transcript into structured notes:\\n\\n{transcript[:15000]}\"}],\n",
    "            temperature=0.3,\n",
    "            max_tokens=1200\n",
    "        )\n",
    "        return resp.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Mistral error: {e}\")\n",
    "        return None\n",
    "def generate_summary(transcript: str) -> str:\n",
    "    # Try providers in order\n",
    "    summary = summarize_with_apify(transcript)\n",
    "    if summary: return summary\n",
    "   \n",
    "    summary = summarize_with_groq(transcript)\n",
    "    if summary: return summary\n",
    "       \n",
    "    summary = summarize_with_mistral(transcript)\n",
    "    if summary: return summary\n",
    "       \n",
    "    raise RuntimeError(\"All summarization providers failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44605130",
   "metadata": {
    "papermill": {
     "duration": 0.026051,
     "end_time": "2025-11-30T18:22:45.135951",
     "exception": false,
     "start_time": "2025-11-30T18:22:45.109900",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Explanation:\n",
    "* Attempts to summarize transcripts using APIfy, Groq, or Mistral in sequence.\n",
    "\n",
    "# 8. Flashcards & Quiz Generation\n",
    "### Purpose: Generates flashcards and quizzes from summaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5543d78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:22:45.188677Z",
     "iopub.status.busy": "2025-11-30T18:22:45.188286Z",
     "iopub.status.idle": "2025-11-30T18:22:45.193105Z",
     "shell.execute_reply": "2025-11-30T18:22:45.192628Z"
    },
    "papermill": {
     "duration": 0.03235,
     "end_time": "2025-11-30T18:22:45.194128",
     "exception": false,
     "start_time": "2025-11-30T18:22:45.161778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Flashcards & Quiz\n",
    "# -------------------------\n",
    "def generate_flashcards(summary: str) -> str:\n",
    "    if not GROQ_KEY: return \"‚ö†Ô∏è GROQ_KEY missing.\"\n",
    "    try:\n",
    "        resp = groq_client.chat.completions.create(\n",
    "            model=\"llama-3.1-8b-instant\",\n",
    "            messages=[{\"role\": \"user\", \"content\":\n",
    "                       f\"Generate 15 Q&A flashcards from this summary. Format: Q: ... A: ...\\n\\n{summary}\"}],\n",
    "            temperature=0.4,\n",
    "            max_tokens=1200\n",
    "        )\n",
    "        return resp.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "def generate_quiz(summary: str) -> str:\n",
    "    if not MISTRAL_KEY: return \"‚ö†Ô∏è MISTRAL_KEY missing.\"\n",
    "    try:\n",
    "        resp = mistral_client.chat.complete(\n",
    "            model=\"mistral-small-2409\",\n",
    "            messages=[{\"role\": \"user\", \"content\":\n",
    "                       f\"Create a 10-question MCQ quiz with answers and rationales based on:\\n{summary}\"}],\n",
    "            temperature=0.4,\n",
    "            max_tokens=1500\n",
    "        )\n",
    "        return resp.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0d844c",
   "metadata": {
    "papermill": {
     "duration": 0.026117,
     "end_time": "2025-11-30T18:22:45.246305",
     "exception": false,
     "start_time": "2025-11-30T18:22:45.220188",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Explanation:\n",
    "* Uses Groq and Mistral to generate flashcards and quizzes.\n",
    "\n",
    "# 9. Export Agent\n",
    "### Purpose: Saves output as a Markdown file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04b64cde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:22:45.299126Z",
     "iopub.status.busy": "2025-11-30T18:22:45.298947Z",
     "iopub.status.idle": "2025-11-30T18:22:45.303075Z",
     "shell.execute_reply": "2025-11-30T18:22:45.302573Z"
    },
    "papermill": {
     "duration": 0.03153,
     "end_time": "2025-11-30T18:22:45.304133",
     "exception": false,
     "start_time": "2025-11-30T18:22:45.272603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Export\n",
    "# -------------------------\n",
    "class ExportAgent:\n",
    "    def save_markdown(self, url: str, transcript: str, summary: str, flashcards: str, quiz: str):\n",
    "        md = f\"\"\"# üìò ShikshaAI Study Pack\n",
    "---\n",
    "## üì∫ URL\n",
    "{url}\n",
    "---\n",
    "## üìù Summary\n",
    "{summary}\n",
    "---\n",
    "## üéØ Flashcards\n",
    "{flashcards}\n",
    "---\n",
    "## üß™ Quiz\n",
    "{quiz}\n",
    "---\n",
    "## üé§ Transcript (Local Whisper)\n",
    "{transcript}\n",
    "\"\"\"\n",
    "        base_id = extract_video_id(url)\n",
    "        output_file = os.path.join(config[\"output_dir\"], f\"ShikshaAI_Output_{safe_filename(base_id)}.md\")\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(md)\n",
    "        logger.info(f\"üìÑ Exported: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5a7130",
   "metadata": {
    "papermill": {
     "duration": 0.025795,
     "end_time": "2025-11-30T18:22:45.358908",
     "exception": false,
     "start_time": "2025-11-30T18:22:45.333113",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Explanation:\n",
    "* Formats and saves the study pack as a Markdown file.\n",
    "\n",
    "# 10. Pipeline & Main Function\n",
    "### Purpose: Orchestrates the entire process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a45f529e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:22:45.413413Z",
     "iopub.status.busy": "2025-11-30T18:22:45.413187Z",
     "iopub.status.idle": "2025-11-30T18:28:32.335157Z",
     "shell.execute_reply": "2025-11-30T18:28:32.334533Z"
    },
    "papermill": {
     "duration": 346.95112,
     "end_time": "2025-11-30T18:28:32.336207",
     "exception": false,
     "start_time": "2025-11-30T18:22:45.385087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 18:22:45,435 - INFO - \n",
      "===== üîÑ Processing: https://youtu.be/h0e2HAPTGF4 =====\n",
      "2025-11-30 18:22:45,436 - INFO - Downloading audio with yt-dlp...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://youtu.be/h0e2HAPTGF4\n",
      "[youtube] h0e2HAPTGF4: Downloading webpage\n",
      "[youtube] h0e2HAPTGF4: Downloading tv downgraded player API JSON\n",
      "[youtube] h0e2HAPTGF4: Downloading web safari player API JSON\n",
      "[youtube] h0e2HAPTGF4: Downloading m3u8 information\n",
      "[info] h0e2HAPTGF4: Downloading 1 format(s): 96\n",
      "[download] Sleeping 6.00 seconds as required by the site...\n",
      "[hlsnative] Downloading m3u8 manifest\n",
      "[hlsnative] Total fragments: 553\n",
      "[download] Destination: temp_h0e2HAPTGF4.mp4\n",
      "[download] 100% of  379.21MiB in 00:00:43 at 8.77MiB/s                   \n",
      "[FixupM3u8] Fixing MPEG-TS in MP4 container of \"temp_h0e2HAPTGF4.mp4\"\n",
      "[ExtractAudio] Destination: temp_h0e2HAPTGF4.mp3\n",
      "Deleting original file temp_h0e2HAPTGF4.mp4 (pass -k to keep)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 18:24:20,561 - INFO - Loading Whisper model: small\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 461M/461M [00:01<00:00, 287MiB/s]\n",
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, mp3, from 'temp_h0e2HAPTGF4.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.76.100\n",
      "  Duration: 00:51:30.42, start: 0.025057, bitrate: 78 kb/s\n",
      "  Stream #0:0: Audio: mp3, 44100 Hz, stereo, fltp, 78 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.13\n",
      "[segment @ 0x5b1277452980] Opening 'chunks/out000.mp3' for writing\n",
      "Output #0, segment, to 'chunks/out%03d.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0: Audio: mp3, 44100 Hz, stereo, fltp, 78 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.13\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "Press [q] to stop, [?] for help\n",
      "[segment @ 0x5b1277452980] Opening 'chunks/out001.mp3' for writing\n",
      "[segment @ 0x5b1277452980] Opening 'chunks/out002.mp3' for writing\n",
      "[segment @ 0x5b1277452980] Opening 'chunks/out003.mp3' for writing\n",
      "[segment @ 0x5b1277452980] Opening 'chunks/out004.mp3' for writing\n",
      "[segment @ 0x5b1277452980] Opening 'chunks/out005.mp3' for writing\n",
      "size=N/A time=00:51:30.36 bitrate=N/A speed=3.38e+03x    \n",
      "video:0kB audio:29586kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
      "2025-11-30 18:28:22,073 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-30 18:28:22,656 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-30 18:28:32,325 - INFO - HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-30 18:28:32,327 - WARNING - WARNING: The model mistral-small-2409 is deprecated and will be removed on 2025-11-30T12:00:00+00:00. Please refer to https://docs.mistral.ai/getting-started/models/#api-versioning for more information.\n",
      "2025-11-30 18:28:32,330 - INFO - üìÑ Exported: ./output/ShikshaAI_Output_h0e2HAPTGF4.md\n",
      "2025-11-30 18:28:32,330 - INFO - üéâ DONE! Study pack for https://youtu.be/h0e2HAPTGF4 is ready.\n",
      "2025-11-30 18:28:32,332 - INFO - Cookies removed from working directory for safety.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------\n",
    "# Pipeline\n",
    "# -------------------------\n",
    "def process_url(url: str):\n",
    "    try:\n",
    "        logger.info(f\"\\n===== üîÑ Processing: {url} =====\")\n",
    "        transcriber = TranscriptAgent(config[\"chunk_length\"])\n",
    "        exporter = ExportAgent()\n",
    "       \n",
    "        transcript = transcriber.transcribe(url)\n",
    "        summary = generate_summary(transcript)\n",
    "        flashcards = generate_flashcards(summary)\n",
    "        quiz = generate_quiz(summary)\n",
    "       \n",
    "        exporter.save_markdown(url, transcript, summary, flashcards, quiz)\n",
    "        logger.info(f\"üéâ DONE! Study pack for {url} is ready.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Error in pipeline for {url}: {e}\")\n",
    "\n",
    "def input_urls() -> list:\n",
    "    # Provide IDs programmatically instead of prompting\n",
    "    ids_raw = config.get(\"video_ids\", \"h0e2HAPTGF4\")  # fallback default\n",
    "    urls = [f\"https://youtu.be/{id.strip()}\" for id in ids_raw.split(\",\") if id.strip()]\n",
    "    return urls\n",
    "\n",
    "        \n",
    "# -------------------------\n",
    "# Safe Cookies Handling\n",
    "# -------------------------\n",
    "def setup_cookies():\n",
    "    \"\"\"\n",
    "    Safely use cookies:\n",
    "    - Copy to /kaggle/working so yt-dlp can write to it\n",
    "    - But delete BEFORE Kaggle generates output\n",
    "    \"\"\"\n",
    "\n",
    "    for root, dirs, files in os.walk(\"/kaggle/input\"):\n",
    "        if \"cookies.txt\" in files:\n",
    "            src = os.path.join(root, \"cookies.txt\")\n",
    "            dst = \"/kaggle/working/cookies.txt\"\n",
    "\n",
    "            import shutil\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "            # Use temporary location for yt-dlp\n",
    "            config[\"cookies_file\"] = dst\n",
    "            return\n",
    "\n",
    "    logger.warning(\"‚ö†Ô∏è No cookies.txt found ‚Äî yt-dlp may fail.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    setup_cookies()\n",
    "    urls = input_urls()  # now returns a list without prompting\n",
    "    try:\n",
    "        with ThreadPoolExecutor(max_workers=config[\"max_workers\"]) as executor:\n",
    "            executor.map(process_url, urls)\n",
    "    except KeyboardInterrupt:\n",
    "        logger.info(\"Process interrupted by user.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå ERROR in main pipeline: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# üßπ DELETE cookies BEFORE Kaggle saves output (SAFE)\n",
    "# ---------------------------------------------------\n",
    "try:\n",
    "    cookies_path = config.get(\"cookies_file\")\n",
    "    if cookies_path and os.path.exists(cookies_path):\n",
    "        os.remove(cookies_path)\n",
    "        logger.info(\"Cookies removed from working directory for safety.\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f3bdca",
   "metadata": {
    "papermill": {
     "duration": 0.043303,
     "end_time": "2025-11-30T18:28:32.424037",
     "exception": false,
     "start_time": "2025-11-30T18:28:32.380734",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Explanation:\n",
    "\n",
    "* process_url: Processes a single URL.\n",
    "* input_urls: Returns a list of YouTube URLs.\n",
    "* setup_cookies: Copies cookies for YouTube authentication.\n",
    "* main: Orchestrates the entire pipeline.\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14484960,
     "sourceId": 121144,
     "sourceType": "competition"
    },
    {
     "datasetId": 8880966,
     "sourceId": 13935525,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 467.694087,
   "end_time": "2025-11-30T18:28:34.649234",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-30T18:20:46.955147",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
